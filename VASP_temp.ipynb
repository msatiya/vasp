{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "metallic-vietnamese",
   "metadata": {},
   "source": [
    "First we need to import utils package and tensorflow with addons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "embedded-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa60cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-connecticut",
   "metadata": {},
   "source": [
    "Next, we define our model. Note that reparametrization trick is done manually - it can be done with tensorflow probability package, which is doing that by itself automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "approved-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagonalToZero(tf.keras.constraints.Constraint):\n",
    "    def __call__(self, w):\n",
    "        \"\"\"Set diagonal to zero\"\"\"\n",
    "        q = tf.linalg.set_diag(w, tf.zeros(w.shape[0:-1]), name=None)\n",
    "        return q\n",
    "\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a basket.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim), stddev=1.)\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VASP(Model):\n",
    "    class Model(tf.keras.Model):\n",
    "        def __init__(self, num_words, latent=1024, hidden=1024, items_sampling=1.):\n",
    "            \"\"\"\n",
    "            num_words             nr of items in dataset (size of tokenizer)\n",
    "            latent                size of latent space\n",
    "            hidden                size of hidden layers\n",
    "            items_sampling        Large items datatsets can be very gpu memory consuming in EASE layer.\n",
    "                                  This coefficient reduces number of ease parametrs by taking only\n",
    "                                  fraction of items sorted by popularity as input for model.\n",
    "                                  Note: This coef should be somewhere around coverage@100 achieved by full\n",
    "                                  size model.\n",
    "                                  For ML20M this coef should be between 0.4888 (coverage@100 for full model)\n",
    "                                  and 1.0\n",
    "                                  For Netflix this coef should be between 0.7055 (coverage@100 for full\n",
    "                                  model) and 1.0\n",
    "            \"\"\"\n",
    "            super(VASP.Model, self).__init__()\n",
    "\n",
    "            self.sampled_items = int(num_words * items_sampling)\n",
    "\n",
    "            assert self.sampled_items > 0\n",
    "            assert self.sampled_items <= num_words\n",
    "\n",
    "            self.s = self.sampled_items < num_words\n",
    "\n",
    "            # ************* ENCODER ***********************\n",
    "            self.encoder1 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln1 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder2 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln2 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder3 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln3 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder4 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln4 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder5 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln5 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder6 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln6 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder7 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln7 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "            # ************* SAMPLING **********************\n",
    "            self.dense_mean = tf.keras.layers.Dense(latent,\n",
    "                                                    name=\"Mean\")\n",
    "            self.dense_log_var = tf.keras.layers.Dense(latent,\n",
    "                                                       name=\"log_var\")\n",
    "\n",
    "            self.sampling = Sampling(name='Sampler')\n",
    "\n",
    "            # ************* DECODER ***********************\n",
    "            self.decoder1 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln1 = tf.keras.layers.LayerNormalization()\n",
    "            self.decoder2 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln2 = tf.keras.layers.LayerNormalization()\n",
    "            self.decoder3 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln3 = tf.keras.layers.LayerNormalization()\n",
    "            self.decoder4 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln4 = tf.keras.layers.LayerNormalization()\n",
    "            self.decoder5 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln5 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "            self.decoder_resnet = tf.keras.layers.Dense(self.sampled_items,\n",
    "                                                        activation='sigmoid',\n",
    "                                                        name=\"DecoderR\")\n",
    "            self.decoder_latent = tf.keras.layers.Dense(self.sampled_items,\n",
    "                                                        activation='sigmoid',\n",
    "                                                        name=\"DecoderL\")\n",
    "\n",
    "            # ************* PARALLEL SHALLOW PATH *********\n",
    "\n",
    "            self.ease = tf.keras.layers.Dense(\n",
    "                self.sampled_items,\n",
    "                activation='sigmoid',\n",
    "                use_bias=False,\n",
    "                kernel_constraint=DiagonalToZero(),  # critical to prevent learning simple identity\n",
    "            )\n",
    "\n",
    "        def call(self, x, training=None):\n",
    "            sampling = self.s\n",
    "            if sampling:\n",
    "                sampled_x = x[:, :self.sampled_items]\n",
    "                non_sampled = x[:, self.sampled_items:] * 0.\n",
    "            else:\n",
    "                sampled_x = x\n",
    "\n",
    "            z_mean, z_log_var, z = self.encode(sampled_x)\n",
    "            if training:\n",
    "                d = self.decode(z)\n",
    "                # Add KL divergence regularization loss.\n",
    "                kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "                kl_loss = tf.reduce_mean(kl_loss)\n",
    "                kl_loss *= -0.5\n",
    "                self.add_loss(kl_loss)\n",
    "                self.add_metric(kl_loss, name=\"kl_div\")\n",
    "            else:\n",
    "                d = self.decode(z_mean)\n",
    "\n",
    "            if sampling:\n",
    "                d = tf.concat([d, non_sampled], axis=-1)\n",
    "\n",
    "            ease = self.ease(sampled_x)\n",
    "\n",
    "            if sampling:\n",
    "                ease = tf.concat([ease, non_sampled], axis=-1)\n",
    "\n",
    "            return d * ease\n",
    "\n",
    "        def decode(self, x):\n",
    "            e0 = x\n",
    "            e1 = self.dln1(tf.keras.activations.swish(self.decoder1(e0)))\n",
    "            e2 = self.dln2(tf.keras.activations.swish(self.decoder2(e1) + e1))\n",
    "            e3 = self.dln3(tf.keras.activations.swish(self.decoder3(e2) + e1 + e2))\n",
    "            e4 = self.dln4(tf.keras.activations.swish(self.decoder4(e3) + e1 + e2 + e3))\n",
    "            e5 = self.dln5(tf.keras.activations.swish(self.decoder5(e4) + e1 + e2 + e3 + e4))\n",
    "\n",
    "            dr = self.decoder_resnet(e5)\n",
    "            dl = self.decoder_latent(x)\n",
    "\n",
    "            return dr * dl\n",
    "\n",
    "        def encode(self, x):\n",
    "            e0 = x\n",
    "            e1 = self.ln1(tf.keras.activations.swish(self.encoder1(e0)))\n",
    "            e2 = self.ln2(tf.keras.activations.swish(self.encoder2(e1) + e1))\n",
    "            e3 = self.ln3(tf.keras.activations.swish(self.encoder3(e2) + e1 + e2))\n",
    "            e4 = self.ln4(tf.keras.activations.swish(self.encoder4(e3) + e1 + e2 + e3))\n",
    "            e5 = self.ln5(tf.keras.activations.swish(self.encoder5(e4) + e1 + e2 + e3 + e4))\n",
    "            e6 = self.ln6(tf.keras.activations.swish(self.encoder6(e5) + e1 + e2 + e3 + e4 + e5))\n",
    "            e7 = self.ln7(tf.keras.activations.swish(self.encoder7(e6) + e1 + e2 + e3 + e4 + e5 + e6))\n",
    "\n",
    "            z_mean = self.dense_mean(e7)\n",
    "            z_log_var = self.dense_log_var(e7)\n",
    "            z = self.sampling((z_mean, z_log_var))\n",
    "\n",
    "            return z_mean, z_log_var, z\n",
    "\n",
    "    def create_model(self, latent=2048, hidden=4096, ease_items_sampling=1., summary=False):\n",
    "        self.model = VASP.Model(self.dataset.num_words, latent, hidden, ease_items_sampling)\n",
    "        self.model(self.split.train_gen[0][0])\n",
    "        if summary:\n",
    "            self.model.summary()\n",
    "        self.mc = MetricsCallback(self)\n",
    "\n",
    "    def compile_model(self, lr=0.00002, fl_alpha=0.25, fl_gamma=2.0):\n",
    "        \"\"\"\n",
    "        lr         learning rate of Nadam optimizer\n",
    "        fl_alpha   alpha parameter of focal crossentropy\n",
    "        fl_gamma   gamma parameter of focal crossentropy\n",
    "        \"\"\"\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Nadam(lr),\n",
    "            loss=lambda x, y: tfa.losses.sigmoid_focal_crossentropy(x, y, alpha=fl_alpha, gamma=fl_gamma),\n",
    "            metrics=['mse', cosine_loss]\n",
    "        )\n",
    "\n",
    "    def train_model(self, epochs=150):\n",
    "        self.model.fit(\n",
    "            self.split.train_gen,\n",
    "            validation_data=self.split.validation_gen,\n",
    "            epochs=epochs,\n",
    "            callbacks=[self.mc]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f47522b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uId</th>\n",
       "      <th>iId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296532</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296532</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>296532</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296532</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296532</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8956474</th>\n",
       "      <td>351491</td>\n",
       "      <td>15469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8956475</th>\n",
       "      <td>351491</td>\n",
       "      <td>15827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8956476</th>\n",
       "      <td>351491</td>\n",
       "      <td>16436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8956477</th>\n",
       "      <td>351491</td>\n",
       "      <td>16762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8956478</th>\n",
       "      <td>351491</td>\n",
       "      <td>17619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45516928 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            uId    iId\n",
       "0        296532    172\n",
       "1        296532    294\n",
       "2        296532    328\n",
       "3        296532    456\n",
       "4        296532    526\n",
       "...         ...    ...\n",
       "8956474  351491  15469\n",
       "8956475  351491  15827\n",
       "8956476  351491  16436\n",
       "8956477  351491  16762\n",
       "8956478  351491  17619\n",
       "\n",
       "[45516928 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_te = pd.read_csv(\"/home/ubuntu/pllm_llm/Datasets/Netflix-Prize/preprocessed/train_te.csv\")\n",
    "temp_tr = pd.read_csv(\"/home/ubuntu/pllm_llm/Datasets/Netflix-Prize/preprocessed/train_tr.csv\")\n",
    "train = pd.concat([temp_tr, temp_te])\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-ambassador",
   "metadata": {},
   "source": [
    "Now, we can load previously preprocessed dataset. We also load pre-defined train/test/validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "medium-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading users_pu5\n",
      "Reading items_pu5\n",
      "Reading purchases_txt_pu5\n",
      "Reading items_sorted_pu5\n",
      "Reading users_sorted_pu5\n",
      "Read all in 0.8546507358551025\n",
      "Tokenizer trained for 20721 items.\n"
     ]
    }
   ],
   "source": [
    "dataset = Data(d='', pruning='u5')\n",
    "#dataset.splits = []\n",
    "#dataset.create_splits(1, 10000, shuffle=False, generators=False)\n",
    "#dataset.split.train_users = pd.read_json(\"train_users.json\").userid.apply(str).to_frame()\n",
    "#dataset.split.validation_users = pd.read_json(\"val_users.json\").userid.apply(str).to_frame()\n",
    "#dataset.split.test_users = pd.read_json(\"test_users.json\").userid.apply(str).to_frame()\n",
    "#dataset.split.generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-handling",
   "metadata": {},
   "source": [
    "Now we can create an instance of our model and train it.\n",
    "\n",
    "For validation during training we sample 80% of the user's interactions randomly as input for the model, and then we measure Recall@20, Recall@50 and NDCG@100 for predicted interactions against the remaining 20% of the user's interactions.\n",
    "\n",
    "This method can give different results for different seeds, but since it is used for validation during training only, it's good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intellectual-mumbai",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  28008448  \n",
      "                                                                 \n",
      " layer_normalization (LayerN  multiple                 8192      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_1 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_2 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_3 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_4 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_5 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_6 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " Mean (Dense)                multiple                  8390656   \n",
      "                                                                 \n",
      " log_var (Dense)             multiple                  8390656   \n",
      "                                                                 \n",
      " Sampler (Sampling)          multiple                  0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  8392704   \n",
      "                                                                 \n",
      " layer_normalization_7 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_8 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_9 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_10 (Lay  multiple                 8192      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_11 (Dense)            multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_11 (Lay  multiple                 8192      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " DecoderR (Dense)            multiple                  28011189  \n",
      "                                                                 \n",
      " DecoderL (Dense)            multiple                  14009013  \n",
      "                                                                 \n",
      " dense_12 (Dense)            multiple                  46744569  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,858,659\n",
      "Trainable params: 309,858,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "================================================================================\n",
      "Train for 50 epochs with lr 0.00005\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "32/32 [==============================] - 1s 4ms/step loss: 21.1263 - mse: 0.0031 - cosine_loss: 0.8498 - kl_div: 0\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.2281 Recall@20=0.2982 Recall@50=0.4158 NCDG@100=0.3254 Coverage@5=0.0225 Coverage@20=0.042 Coverage@50=0.0645 Coverage@100=0.0891 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 156s 1s/step - loss: 21.1263 - mse: 0.0031 - cosine_loss: 0.8498 - kl_div: 0.9760 - val_loss: 25.6863 - val_mse: 0.0038 - val_cosine_loss: 0.7379 - val_kl_div: 0.0000e+00\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 15.9058 - mse: 0.0023 - cosine_loss: 0.8031 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.2612 Recall@20=0.3299 Recall@50=0.4533 NCDG@100=0.3587 Coverage@5=0.0358 Coverage@20=0.0629 Coverage@50=0.0917 Coverage@100=0.1211 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 172s 2s/step - loss: 15.9058 - mse: 0.0023 - cosine_loss: 0.8031 - kl_div: 0.4431 - val_loss: 24.2548 - val_mse: 0.0036 - val_cosine_loss: 0.7108 - val_kl_div: 0.0000e+00\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 15.3389 - mse: 0.0022 - cosine_loss: 0.7879 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.2767 Recall@20=0.3439 Recall@50=0.471 NCDG@100=0.3742 Coverage@5=0.0435 Coverage@20=0.0786 Coverage@50=0.1103 Coverage@100=0.1444 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 173s 2s/step - loss: 15.3389 - mse: 0.0022 - cosine_loss: 0.7879 - kl_div: 0.3581 - val_loss: 23.7152 - val_mse: 0.0035 - val_cosine_loss: 0.7008 - val_kl_div: 0.0000e+00\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 15.0182 - mse: 0.0022 - cosine_loss: 0.7791 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Model metrics:Recall@5=0.2864 Recall@20=0.3542 Recall@50=0.4807 NCDG@100=0.3832 Coverage@5=0.0469 Coverage@20=0.0858 Coverage@50=0.1221 Coverage@100=0.1588 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 172s 2s/step - loss: 15.0182 - mse: 0.0022 - cosine_loss: 0.7791 - kl_div: 0.3191 - val_loss: 23.4706 - val_mse: 0.0034 - val_cosine_loss: 0.6933 - val_kl_div: 0.0000e+00\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 14.8479 - mse: 0.0022 - cosine_loss: 0.7725 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.2937 Recall@20=0.3616 Recall@50=0.4877 NCDG@100=0.3904 Coverage@5=0.0514 Coverage@20=0.0931 Coverage@50=0.1326 Coverage@100=0.1707 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 173s 2s/step - loss: 14.8479 - mse: 0.0022 - cosine_loss: 0.7725 - kl_div: 0.2984 - val_loss: 23.3325 - val_mse: 0.0035 - val_cosine_loss: 0.6958 - val_kl_div: 0.0000e+00\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 14.6793 - mse: 0.0021 - cosine_loss: 0.7672 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.2989 Recall@20=0.367 Recall@50=0.4944 NCDG@100=0.3951 Coverage@5=0.0537 Coverage@20=0.0973 Coverage@50=0.1401 Coverage@100=0.18 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 172s 2s/step - loss: 14.6793 - mse: 0.0021 - cosine_loss: 0.7672 - kl_div: 0.2874 - val_loss: 23.2867 - val_mse: 0.0034 - val_cosine_loss: 0.6941 - val_kl_div: 0.0000e+00\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 14.5291 - mse: 0.0021 - cosine_loss: 0.7629 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3049 Recall@20=0.3722 Recall@50=0.5006 NCDG@100=0.4007 Coverage@5=0.0544 Coverage@20=0.1013 Coverage@50=0.1464 Coverage@100=0.1878 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 172s 2s/step - loss: 14.5291 - mse: 0.0021 - cosine_loss: 0.7629 - kl_div: 0.2812 - val_loss: 23.3245 - val_mse: 0.0034 - val_cosine_loss: 0.6946 - val_kl_div: 0.0000e+00\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 14.4423 - mse: 0.0021 - cosine_loss: 0.7591 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3084 Recall@20=0.3754 Recall@50=0.5041 NCDG@100=0.4044 Coverage@5=0.0576 Coverage@20=0.1074 Coverage@50=0.1528 Coverage@100=0.1979 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 172s 2s/step - loss: 14.4423 - mse: 0.0021 - cosine_loss: 0.7591 - kl_div: 0.2782 - val_loss: 23.4274 - val_mse: 0.0034 - val_cosine_loss: 0.6973 - val_kl_div: 0.0000e+00\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 14.3529 - mse: 0.0021 - cosine_loss: 0.7558 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3091 Recall@20=0.3783 Recall@50=0.5082 NCDG@100=0.4065 Coverage@5=0.0578 Coverage@20=0.11 Coverage@50=0.157 Coverage@100=0.2013 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 14.3529 - mse: 0.0021 - cosine_loss: 0.7558 - kl_div: 0.2776 - val_loss: 23.6275 - val_mse: 0.0035 - val_cosine_loss: 0.7029 - val_kl_div: 0.0000e+00\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 14.2576 - mse: 0.0021 - cosine_loss: 0.7528 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3134 Recall@20=0.3814 Recall@50=0.5124 NCDG@100=0.4108 Coverage@5=0.061 Coverage@20=0.1156 Coverage@50=0.1643 Coverage@100=0.211 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 14.2576 - mse: 0.0021 - cosine_loss: 0.7528 - kl_div: 0.2774 - val_loss: 23.7313 - val_mse: 0.0034 - val_cosine_loss: 0.7026 - val_kl_div: 0.0000e+00\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 14.1647 - mse: 0.0021 - cosine_loss: 0.7504 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3137 Recall@20=0.3834 Recall@50=0.5153 NCDG@100=0.4124 Coverage@5=0.0582 Coverage@20=0.1146 Coverage@50=0.1641 Coverage@100=0.2117 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 14.1647 - mse: 0.0021 - cosine_loss: 0.7504 - kl_div: 0.2780 - val_loss: 23.9077 - val_mse: 0.0033 - val_cosine_loss: 0.7028 - val_kl_div: 0.0000e+00\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 14.1026 - mse: 0.0021 - cosine_loss: 0.7481 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3154 Recall@20=0.3852 Recall@50=0.5173 NCDG@100=0.4156 Coverage@5=0.0597 Coverage@20=0.1188 Coverage@50=0.1699 Coverage@100=0.2175 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 172s 2s/step - loss: 14.1026 - mse: 0.0021 - cosine_loss: 0.7481 - kl_div: 0.2796 - val_loss: 24.1690 - val_mse: 0.0034 - val_cosine_loss: 0.7088 - val_kl_div: 0.0000e+00\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 14.0199 - mse: 0.0020 - cosine_loss: 0.7457 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.317 Recall@20=0.3872 Recall@50=0.5188 NCDG@100=0.417 Coverage@5=0.0603 Coverage@20=0.1205 Coverage@50=0.1725 Coverage@100=0.2192 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 14.0199 - mse: 0.0020 - cosine_loss: 0.7457 - kl_div: 0.2811 - val_loss: 24.5066 - val_mse: 0.0035 - val_cosine_loss: 0.7156 - val_kl_div: 0.0000e+00\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.9578 - mse: 0.0020 - cosine_loss: 0.7437 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3211 Recall@20=0.3891 Recall@50=0.5217 NCDG@100=0.4198 Coverage@5=0.0598 Coverage@20=0.1214 Coverage@50=0.177 Coverage@100=0.224 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 13.9578 - mse: 0.0020 - cosine_loss: 0.7437 - kl_div: 0.2835 - val_loss: 24.6812 - val_mse: 0.0034 - val_cosine_loss: 0.7147 - val_kl_div: 0.0000e+00\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.9058 - mse: 0.0020 - cosine_loss: 0.7419 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.323 Recall@20=0.3909 Recall@50=0.5233 NCDG@100=0.4217 Coverage@5=0.0625 Coverage@20=0.1259 Coverage@50=0.1812 Coverage@100=0.2289 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 13.9058 - mse: 0.0020 - cosine_loss: 0.7419 - kl_div: 0.2859 - val_loss: 25.1051 - val_mse: 0.0035 - val_cosine_loss: 0.7214 - val_kl_div: 0.0000e+00\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.8291 - mse: 0.0020 - cosine_loss: 0.7399 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3233 Recall@20=0.3923 Recall@50=0.5258 NCDG@100=0.4233 Coverage@5=0.0649 Coverage@20=0.1296 Coverage@50=0.1877 Coverage@100=0.2356 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 173s 2s/step - loss: 13.8291 - mse: 0.0020 - cosine_loss: 0.7399 - kl_div: 0.2880 - val_loss: 25.5744 - val_mse: 0.0035 - val_cosine_loss: 0.7280 - val_kl_div: 0.0000e+00\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.7838 - mse: 0.0020 - cosine_loss: 0.7382 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3246 Recall@20=0.3945 Recall@50=0.5276 NCDG@100=0.4253 Coverage@5=0.0639 Coverage@20=0.1302 Coverage@50=0.1888 Coverage@100=0.2363 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 13.7838 - mse: 0.0020 - cosine_loss: 0.7382 - kl_div: 0.2904 - val_loss: 25.7604 - val_mse: 0.0034 - val_cosine_loss: 0.7252 - val_kl_div: 0.0000e+00\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.7155 - mse: 0.0020 - cosine_loss: 0.7368 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3265 Recall@20=0.3952 Recall@50=0.5287 NCDG@100=0.4259 Coverage@5=0.0613 Coverage@20=0.1305 Coverage@50=0.1906 Coverage@100=0.239 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 13.7155 - mse: 0.0020 - cosine_loss: 0.7368 - kl_div: 0.2914 - val_loss: 26.1045 - val_mse: 0.0034 - val_cosine_loss: 0.7308 - val_kl_div: 0.0000e+00\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.6727 - mse: 0.0020 - cosine_loss: 0.7351 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3276 Recall@20=0.3957 Recall@50=0.5303 NCDG@100=0.427 Coverage@5=0.06 Coverage@20=0.1278 Coverage@50=0.1889 Coverage@100=0.2392 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 170s 2s/step - loss: 13.6727 - mse: 0.0020 - cosine_loss: 0.7351 - kl_div: 0.2939 - val_loss: 26.3403 - val_mse: 0.0034 - val_cosine_loss: 0.7310 - val_kl_div: 0.0000e+00\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.5819 - mse: 0.0020 - cosine_loss: 0.7337 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3276 Recall@20=0.397 Recall@50=0.5296 NCDG@100=0.4275 Coverage@5=0.0601 Coverage@20=0.1277 Coverage@50=0.189 Coverage@100=0.2378 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "112/112 [==============================] - 141s 1s/step - loss: 13.5819 - mse: 0.0020 - cosine_loss: 0.7337 - kl_div: 0.2952 - val_loss: 26.8060 - val_mse: 0.0035 - val_cosine_loss: 0.7384 - val_kl_div: 0.0000e+00\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.5596 - mse: 0.0020 - cosine_loss: 0.7322 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3288 Recall@20=0.3973 Recall@50=0.5308 NCDG@100=0.4288 Coverage@5=0.0636 Coverage@20=0.1346 Coverage@50=0.1942 Coverage@100=0.2458 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 169s 2s/step - loss: 13.5596 - mse: 0.0020 - cosine_loss: 0.7322 - kl_div: 0.2971 - val_loss: 27.6239 - val_mse: 0.0036 - val_cosine_loss: 0.7482 - val_kl_div: 0.0000e+00\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.5036 - mse: 0.0020 - cosine_loss: 0.7309 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3305 Recall@20=0.3992 Recall@50=0.5324 NCDG@100=0.43 Coverage@5=0.0606 Coverage@20=0.1321 Coverage@50=0.1936 Coverage@100=0.2458 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 170s 2s/step - loss: 13.5036 - mse: 0.0020 - cosine_loss: 0.7309 - kl_div: 0.2994 - val_loss: 27.6318 - val_mse: 0.0035 - val_cosine_loss: 0.7445 - val_kl_div: 0.0000e+00\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.4357 - mse: 0.0020 - cosine_loss: 0.7296 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3304 Recall@20=0.4006 Recall@50=0.5341 NCDG@100=0.4311 Coverage@5=0.0598 Coverage@20=0.1319 Coverage@50=0.1958 Coverage@100=0.2467 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 13.4357 - mse: 0.0020 - cosine_loss: 0.7296 - kl_div: 0.3010 - val_loss: 27.8882 - val_mse: 0.0035 - val_cosine_loss: 0.7452 - val_kl_div: 0.0000e+00\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.4018 - mse: 0.0019 - cosine_loss: 0.7282 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3326 Recall@20=0.4015 Recall@50=0.5359 NCDG@100=0.4316 Coverage@5=0.0591 Coverage@20=0.1305 Coverage@50=0.1943 Coverage@100=0.2473 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 13.4018 - mse: 0.0019 - cosine_loss: 0.7282 - kl_div: 0.3033 - val_loss: 28.1938 - val_mse: 0.0035 - val_cosine_loss: 0.7489 - val_kl_div: 0.0000e+00\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.3644 - mse: 0.0019 - cosine_loss: 0.7270 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3335 Recall@20=0.4021 Recall@50=0.5366 NCDG@100=0.4328 Coverage@5=0.0581 Coverage@20=0.1306 Coverage@50=0.1979 Coverage@100=0.2491 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 171s 2s/step - loss: 13.3644 - mse: 0.0019 - cosine_loss: 0.7270 - kl_div: 0.3054 - val_loss: 28.6957 - val_mse: 0.0036 - val_cosine_loss: 0.7536 - val_kl_div: 0.0000e+00\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.3196 - mse: 0.0019 - cosine_loss: 0.7257 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3331 Recall@20=0.4033 Recall@50=0.5362 NCDG@100=0.4337 Coverage@5=0.0637 Coverage@20=0.14 Coverage@50=0.2064 Coverage@100=0.2582 \n",
      "New best for NCDG@100\n",
      "New best for Recall@20\n",
      "112/112 [==============================] - 141s 1s/step - loss: 13.3196 - mse: 0.0019 - cosine_loss: 0.7257 - kl_div: 0.3072 - val_loss: 29.5195 - val_mse: 0.0036 - val_cosine_loss: 0.7608 - val_kl_div: 0.0000e+00\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.2504 - mse: 0.0019 - cosine_loss: 0.7246 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3338 Recall@20=0.4033 Recall@50=0.5375 NCDG@100=0.4334 Coverage@5=0.0556 Coverage@20=0.1246 Coverage@50=0.1922 Coverage@100=0.2458 \n",
      "New best for Recall@20\n",
      "New best for Recall@50\n",
      "112/112 [==============================] - 140s 1s/step - loss: 13.2504 - mse: 0.0019 - cosine_loss: 0.7246 - kl_div: 0.3095 - val_loss: 28.7595 - val_mse: 0.0035 - val_cosine_loss: 0.7493 - val_kl_div: 0.0000e+00\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 4ms/step loss: 13.2268 - mse: 0.0019 - cosine_loss: 0.7234 - kl_div: \n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "Model metrics:Recall@5=0.3336 Recall@20=0.4047 Recall@50=0.5384 NCDG@100=0.4342 Coverage@5=0.0624 Coverage@20=0.1385 Coverage@50=0.2059 Coverage@100=0.2595 \n",
      "New best for NCDG@100\n"
     ]
    }
   ],
   "source": [
    "m = VASP(dataset.split, name=\"VASP_ML20_1\")\n",
    "m.create_model(latent=2048, hidden=4096, ease_items_sampling=0.33)\n",
    "#m.model.summary()\n",
    "print(\"=\" * 80)\n",
    "print(\"Train for 50 epochs with lr 0.00005\")\n",
    "m.compile_model(lr=0.00005, fl_alpha=0.25, fl_gamma=2.0)\n",
    "m.train_model(50)\n",
    "print(\"=\" * 80)\n",
    "print(\"Than train for 20 epochs with lr 0.00001\")\n",
    "m.compile_model(lr=0.00001, fl_alpha=0.25, fl_gamma=2.0)\n",
    "m.train_model(20)\n",
    "print(\"=\" * 80)\n",
    "print(\"Than train for 20 epochs with lr 0.000001\")\n",
    "m.compile_model(lr=0.00001, fl_alpha=0.25, fl_gamma=2.0)\n",
    "m.train_model(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-fantasy",
   "metadata": {},
   "source": [
    "Dataframe with the details of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.mc.get_history_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-collins",
   "metadata": {},
   "source": [
    "And the details of the training as a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.mc.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-payroll",
   "metadata": {},
   "source": [
    "For final evaluation we do 5-fold validation on the user's interaction history. We think that this is more objective measure than only hide sampled 20% of the user's interactions randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold evaluation on the test set\n",
    "\n",
    "test_r20s = []\n",
    "test_r50s = []\n",
    "test_n100s = []\n",
    "\n",
    "for fold in range(1,6):\n",
    "    ev=Evaluator(m.split, method=str(fold)+'_20')\n",
    "    ev.update(m.model)\n",
    "\n",
    "    test_n100s.append(ev.get_ncdg(100))\n",
    "    test_r20s.append(ev.get_recall(20))\n",
    "    test_r50s.append(ev.get_recall(50))\n",
    "\n",
    "print(\"TEST SET (MEAN)\")\n",
    "print(\"5-fold mean NCDG@100\", round(sum(test_n100s) / len(test_n100s),3))\n",
    "print(\"5-fold mean Recall@20\", round(sum(test_r20s) / len(test_r20s),3))\n",
    "print(\"5-fold mean Recall@50\", round(sum(test_r50s) / len(test_r50s),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-committee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
