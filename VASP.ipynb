{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "metallic-vietnamese",
   "metadata": {},
   "source": [
    "First we need to import utils package and tensorflow with addons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "embedded-portuguese",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 22:29:44.976431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 22:29:45.716894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-04-26 22:29:45.716980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-04-26 22:29:45.716986: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ubuntu/.local/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa60cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-connecticut",
   "metadata": {},
   "source": [
    "Next, we define our model. Note that reparametrization trick is done manually - it can be done with tensorflow probability package, which is doing that by itself automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approved-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagonalToZero(tf.keras.constraints.Constraint):\n",
    "    def __call__(self, w):\n",
    "        \"\"\"Set diagonal to zero\"\"\"\n",
    "        q = tf.linalg.set_diag(w, tf.zeros(w.shape[0:-1]), name=None)\n",
    "        return q\n",
    "\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a basket.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim), stddev=1.)\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VASP(Model):\n",
    "    class Model(tf.keras.Model):\n",
    "        def __init__(self, num_words, latent=1024, hidden=1024, items_sampling=1.):\n",
    "            \"\"\"\n",
    "            num_words             nr of items in dataset (size of tokenizer)\n",
    "            latent                size of latent space\n",
    "            hidden                size of hidden layers\n",
    "            items_sampling        Large items datatsets can be very gpu memory consuming in EASE layer.\n",
    "                                  This coefficient reduces number of ease parametrs by taking only\n",
    "                                  fraction of items sorted by popularity as input for model.\n",
    "                                  Note: This coef should be somewhere around coverage@100 achieved by full\n",
    "                                  size model.\n",
    "                                  For ML20M this coef should be between 0.4888 (coverage@100 for full model)\n",
    "                                  and 1.0\n",
    "                                  For Netflix this coef should be between 0.7055 (coverage@100 for full\n",
    "                                  model) and 1.0\n",
    "            \"\"\"\n",
    "            super(VASP.Model, self).__init__()\n",
    "\n",
    "            self.sampled_items = int(num_words * items_sampling)\n",
    "\n",
    "            assert self.sampled_items > 0\n",
    "            assert self.sampled_items <= num_words\n",
    "\n",
    "            self.s = self.sampled_items < num_words\n",
    "\n",
    "            # ************* ENCODER ***********************\n",
    "            self.encoder1 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln1 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder2 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln2 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder3 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln3 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder4 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln4 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder5 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln5 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder6 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln6 = tf.keras.layers.LayerNormalization()\n",
    "            self.encoder7 = tf.keras.layers.Dense(hidden)\n",
    "            self.ln7 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "            # ************* SAMPLING **********************\n",
    "            self.dense_mean = tf.keras.layers.Dense(latent,\n",
    "                                                    name=\"Mean\")\n",
    "            self.dense_log_var = tf.keras.layers.Dense(latent,\n",
    "                                                       name=\"log_var\")\n",
    "\n",
    "            self.sampling = Sampling(name='Sampler')\n",
    "\n",
    "            # ************* DECODER ***********************\n",
    "            self.decoder1 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln1 = tf.keras.layers.LayerNormalization()\n",
    "            self.decoder2 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln2 = tf.keras.layers.LayerNormalization()\n",
    "            self.decoder3 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln3 = tf.keras.layers.LayerNormalization()\n",
    "            self.decoder4 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln4 = tf.keras.layers.LayerNormalization()\n",
    "            self.decoder5 = tf.keras.layers.Dense(hidden)\n",
    "            self.dln5 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "            self.decoder_resnet = tf.keras.layers.Dense(self.sampled_items,\n",
    "                                                        activation='sigmoid',\n",
    "                                                        name=\"DecoderR\")\n",
    "            self.decoder_latent = tf.keras.layers.Dense(self.sampled_items,\n",
    "                                                        activation='sigmoid',\n",
    "                                                        name=\"DecoderL\")\n",
    "\n",
    "            # ************* PARALLEL SHALLOW PATH *********\n",
    "\n",
    "            self.ease = tf.keras.layers.Dense(\n",
    "                self.sampled_items,\n",
    "                activation='sigmoid',\n",
    "                use_bias=False,\n",
    "                kernel_constraint=DiagonalToZero(),  # critical to prevent learning simple identity\n",
    "            )\n",
    "\n",
    "        def call(self, x, training=None):\n",
    "            sampling = self.s\n",
    "            if sampling:\n",
    "                sampled_x = x[:, :self.sampled_items]\n",
    "                non_sampled = x[:, self.sampled_items:] * 0.\n",
    "            else:\n",
    "                sampled_x = x\n",
    "\n",
    "            z_mean, z_log_var, z = self.encode(sampled_x)\n",
    "            if training:\n",
    "                d = self.decode(z)\n",
    "                # Add KL divergence regularization loss.\n",
    "                kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "                kl_loss = tf.reduce_mean(kl_loss)\n",
    "                kl_loss *= -0.5\n",
    "                self.add_loss(kl_loss)\n",
    "                self.add_metric(kl_loss, name=\"kl_div\")\n",
    "            else:\n",
    "                d = self.decode(z_mean)\n",
    "\n",
    "            if sampling:\n",
    "                d = tf.concat([d, non_sampled], axis=-1)\n",
    "\n",
    "            ease = self.ease(sampled_x)\n",
    "\n",
    "            if sampling:\n",
    "                ease = tf.concat([ease, non_sampled], axis=-1)\n",
    "\n",
    "            return d * ease\n",
    "\n",
    "        def decode(self, x):\n",
    "            e0 = x\n",
    "            e1 = self.dln1(tf.keras.activations.swish(self.decoder1(e0)))\n",
    "            e2 = self.dln2(tf.keras.activations.swish(self.decoder2(e1) + e1))\n",
    "            e3 = self.dln3(tf.keras.activations.swish(self.decoder3(e2) + e1 + e2))\n",
    "            e4 = self.dln4(tf.keras.activations.swish(self.decoder4(e3) + e1 + e2 + e3))\n",
    "            e5 = self.dln5(tf.keras.activations.swish(self.decoder5(e4) + e1 + e2 + e3 + e4))\n",
    "\n",
    "            dr = self.decoder_resnet(e5)\n",
    "            dl = self.decoder_latent(x)\n",
    "\n",
    "            return dr * dl\n",
    "\n",
    "        def encode(self, x):\n",
    "            e0 = x\n",
    "            e1 = self.ln1(tf.keras.activations.swish(self.encoder1(e0)))\n",
    "            e2 = self.ln2(tf.keras.activations.swish(self.encoder2(e1) + e1))\n",
    "            e3 = self.ln3(tf.keras.activations.swish(self.encoder3(e2) + e1 + e2))\n",
    "            e4 = self.ln4(tf.keras.activations.swish(self.encoder4(e3) + e1 + e2 + e3))\n",
    "            e5 = self.ln5(tf.keras.activations.swish(self.encoder5(e4) + e1 + e2 + e3 + e4))\n",
    "            e6 = self.ln6(tf.keras.activations.swish(self.encoder6(e5) + e1 + e2 + e3 + e4 + e5))\n",
    "            e7 = self.ln7(tf.keras.activations.swish(self.encoder7(e6) + e1 + e2 + e3 + e4 + e5 + e6))\n",
    "\n",
    "            z_mean = self.dense_mean(e7)\n",
    "            z_log_var = self.dense_log_var(e7)\n",
    "            z = self.sampling((z_mean, z_log_var))\n",
    "\n",
    "            return z_mean, z_log_var, z\n",
    "\n",
    "    def create_model(self, latent=2048, hidden=4096, ease_items_sampling=1., summary=False):\n",
    "        self.model = VASP.Model(self.dataset.num_words, latent, hidden, ease_items_sampling)\n",
    "        self.model(self.split.train_gen[0][0])\n",
    "        if summary:\n",
    "            self.model.summary()\n",
    "        self.mc = MetricsCallback(self)\n",
    "\n",
    "    def compile_model(self, lr=0.00002, fl_alpha=0.25, fl_gamma=2.0):\n",
    "        \"\"\"\n",
    "        lr         learning rate of Nadam optimizer\n",
    "        fl_alpha   alpha parameter of focal crossentropy\n",
    "        fl_gamma   gamma parameter of focal crossentropy\n",
    "        \"\"\"\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Nadam(lr),\n",
    "            loss=lambda x, y: tfa.losses.sigmoid_focal_crossentropy(x, y, alpha=fl_alpha, gamma=fl_gamma),\n",
    "            metrics=['mse', cosine_loss]\n",
    "        )\n",
    "\n",
    "    def train_model(self, epochs=150):\n",
    "        self.model.fit(\n",
    "            self.split.train_gen,\n",
    "            validation_data=self.split.validation_gen,\n",
    "            epochs=epochs,\n",
    "            callbacks=[self.mc]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-ambassador",
   "metadata": {},
   "source": [
    "Now, we can load previously preprocessed dataset. We also load pre-defined train/test/validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medium-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading users_pu5\n",
      "Reading items_pu5\n",
      "Reading purchases_txt_pu5\n",
      "Reading items_sorted_pu5\n",
      "Reading users_sorted_pu5\n",
      "Read all in 0.9094583988189697\n",
      "Tokenizer trained for 20721 items.\n",
      "Creating 1 splits of 100 samples each.\n",
      "Creating split nr. 1\n",
      "SplitGenerator init done in 4.368387222290039 secs.\n",
      "SplitGenerator init done in 0.3719193935394287 secs.\n",
      "SplitGenerator init done in 0.36934947967529297 secs.\n",
      "Creating evaluator\n",
      "Creating test split evaluator with leave_random_20_pct_out method.\n",
      "Creating validation split evaluator with leave_random_20_pct_out method.\n"
     ]
    }
   ],
   "source": [
    "dataset = Data(d='/home/ubuntu/vasp/og_vasp_data/', pruning='u5')\n",
    "dataset.splits = []\n",
    "dataset.create_splits(1, 100, shuffle=False, generators=False)\n",
    "dataset.split.train_users = pd.read_json(\"/home/ubuntu/vasp/og_vasp_data/train_users.json\").userid.apply(str).to_frame()\n",
    "dataset.split.validation_users = pd.read_json(\"/home/ubuntu/vasp/og_vasp_data/val_users.json\").userid.apply(str).to_frame()\n",
    "dataset.split.test_users = pd.read_json(\"/home/ubuntu/vasp/og_vasp_data/test_users.json\").userid.apply(str).to_frame()\n",
    "dataset.split.generators()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-handling",
   "metadata": {},
   "source": [
    "Now we can create an instance of our model and train it.\n",
    "\n",
    "For validation during training we sample 80% of the user's interactions randomly as input for the model, and then we measure Recall@20, Recall@50 and NDCG@100 for predicted interactions against the remaining 20% of the user's interactions.\n",
    "\n",
    "This method can give different results for different seeds, but since it is used for validation during training only, it's good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intellectual-mumbai",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  28008448  \n",
      "                                                                 \n",
      " layer_normalization (LayerN  multiple                 8192      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_1 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_2 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_3 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_4 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_5 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_6 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " Mean (Dense)                multiple                  8390656   \n",
      "                                                                 \n",
      " log_var (Dense)             multiple                  8390656   \n",
      "                                                                 \n",
      " Sampler (Sampling)          multiple                  0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  8392704   \n",
      "                                                                 \n",
      " layer_normalization_7 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_8 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_9 (Laye  multiple                 8192      \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_10 (Lay  multiple                 8192      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_11 (Dense)            multiple                  16781312  \n",
      "                                                                 \n",
      " layer_normalization_11 (Lay  multiple                 8192      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " DecoderR (Dense)            multiple                  28011189  \n",
      "                                                                 \n",
      " DecoderL (Dense)            multiple                  14009013  \n",
      "                                                                 \n",
      " dense_12 (Dense)            multiple                  46744569  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,858,659\n",
      "Trainable params: 309,858,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "================================================================================\n",
      "Train for 50 epochs with lr 0.00005\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:AutoGraph could not transform <function cosine_loss at 0x7f7a71552ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: [Errno 28] No space left on device\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function cosine_loss at 0x7f7a71552ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: [Errno 28] No space left on device\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. Bitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. Klicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. Weitere Details finden Sie in Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "m = VASP(dataset.split, name=\"VASP_ML20_1\")\n",
    "m.create_model(latent=2048, hidden=4096, ease_items_sampling=0.33)\n",
    "m.model.summary()\n",
    "print(\"=\" * 80)\n",
    "print(\"Train for 50 epochs with lr 0.00005\")\n",
    "m.compile_model(lr=0.00005, fl_alpha=0.25, fl_gamma=2.0)\n",
    "m.train_model(50)\n",
    "print(\"=\" * 80)\n",
    "print(\"Than train for 20 epochs with lr 0.00001\")\n",
    "m.compile_model(lr=0.00001, fl_alpha=0.25, fl_gamma=2.0)\n",
    "m.train_model(20)\n",
    "print(\"=\" * 80)\n",
    "print(\"Than train for 20 epochs with lr 0.000001\")\n",
    "m.compile_model(lr=0.00001, fl_alpha=0.25, fl_gamma=2.0)\n",
    "m.train_model(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-fantasy",
   "metadata": {},
   "source": [
    "Dataframe with the details of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.mc.get_history_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-collins",
   "metadata": {},
   "source": [
    "And the details of the training as a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.mc.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-payroll",
   "metadata": {},
   "source": [
    "For final evaluation we do 5-fold validation on the user's interaction history. We think that this is more objective measure than only hide sampled 20% of the user's interactions randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold evaluation on the test set\n",
    "\n",
    "test_r20s = []\n",
    "test_r50s = []\n",
    "test_n100s = []\n",
    "\n",
    "for fold in range(1,6):\n",
    "    ev=Evaluator(m.split, method=str(fold)+'_20')\n",
    "    ev.update(m.model)\n",
    "\n",
    "    test_n100s.append(ev.get_ncdg(100))\n",
    "    test_r20s.append(ev.get_recall(20))\n",
    "    test_r50s.append(ev.get_recall(50))\n",
    "\n",
    "print(\"TEST SET (MEAN)\")\n",
    "print(\"5-fold mean NCDG@100\", round(sum(test_n100s) / len(test_n100s),3))\n",
    "print(\"5-fold mean Recall@20\", round(sum(test_r20s) / len(test_r20s),3))\n",
    "print(\"5-fold mean Recall@50\", round(sum(test_r50s) / len(test_r50s),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-committee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
