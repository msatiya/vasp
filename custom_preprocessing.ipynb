{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "mexican-circus",
   "metadata": {},
   "source": [
    "Run cells bellow to preprocess our **custom** datasets.\n",
    "\n",
    "Estimated time is around 45 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pointed-presentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-oriental",
   "metadata": {},
   "source": [
    "All Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coupled-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_path = \"/home/ubuntu/vasp/Datasets/ml-20m/preprocessed_100\"\n",
    "# ds_path_out = \"/home/ubuntu/vasp/Datasets/ml-20m/preprocessed_vasp\"\n",
    "\n",
    "ds_path = \"/home/ubuntu/vasp/Datasets/netflix/preprocessed_100\"\n",
    "ds_path_out = \"/home/ubuntu/vasp/Datasets/netflix/preprocessed_vasp\"\n",
    "\n",
    "# ds_path = \"/home/ubuntu/vasp/Datasets/steam-200k/preprocessed_100\"\n",
    "# ds_path_out = \"/home/ubuntu/vasp/Datasets/steam-200k/preprocessed_vasp\"\n",
    "\n",
    "Path(ds_path_out).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b872dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid  itemid                                 title\n",
      "0  296532     172                   The Devil's Brigade\n",
      "1  296532     294        Ace Ventura: When Nature Calls\n",
      "2  296532     328                                 Dogma\n",
      "3  296532     456                     Kill Bill: Vol. 2\n",
      "4  296532     526  The Hitchhiker's Guide to the Galaxy\n",
      "45516928\n",
      "   userid  itemid                           title\n",
      "0  409802      29          Something's Gotta Give\n",
      "1  409802     298           Bridget Jones's Diary\n",
      "2  409802     312                  Pay It Forward\n",
      "3  409802     690  The Hand that Rocks the Cradle\n",
      "4  409802     884                             Ray\n",
      "5685127\n",
      "   userid  itemid           title\n",
      "0  458924    3331     The Village\n",
      "1  458924    3369     Whale Rider\n",
      "2  458924    3454  Lost: Season 1\n",
      "3  458924    3487    Time Bandits\n",
      "4  458924    3915    Garden State\n",
      "5677981\n",
      "   userid  itemid                                 title\n",
      "0  296532     172                   The Devil's Brigade\n",
      "1  296532     294        Ace Ventura: When Nature Calls\n",
      "2  296532     328                                 Dogma\n",
      "3  296532     456                     Kill Bill: Vol. 2\n",
      "4  296532     526  The Hitchhiker's Guide to the Galaxy\n",
      "56880036\n"
     ]
    }
   ],
   "source": [
    "temp_tr = pd.read_csv(os.path.join(ds_path, 'train_tr.csv'))\n",
    "temp_te = pd.read_csv(os.path.join(ds_path, 'train_te.csv'))\n",
    "train = pd.concat([temp_tr, temp_te])\n",
    "train.rename({'uId': 'userid', 'iId': 'itemid'}, axis=1, inplace=True)\n",
    "print(train.head())\n",
    "print(len(train))\n",
    "\n",
    "temp_tr = pd.read_csv(os.path.join(ds_path, 'validation_tr.csv'))\n",
    "temp_te = pd.read_csv(os.path.join(ds_path, 'validation_te.csv'))\n",
    "val = pd.concat([temp_tr, temp_te])\n",
    "val.rename({'uId': 'userid', 'iId': 'itemid'}, axis=1, inplace=True)\n",
    "print(val.head())\n",
    "print(len(val))\n",
    "\n",
    "temp_tr = pd.read_csv(os.path.join(ds_path, 'test_tr.csv'))\n",
    "temp_te = pd.read_csv(os.path.join(ds_path, 'test_te.csv'))\n",
    "test = pd.concat([temp_tr, temp_te])\n",
    "test.rename({'uId': 'userid', 'iId': 'itemid'}, axis=1, inplace=True)\n",
    "print(test.head())\n",
    "print(len(test))\n",
    "\n",
    "full = pd.concat([train, val, test])\n",
    "print(full.head())\n",
    "print(len(full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81507d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17763</th>\n",
       "      <td>17766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17764</th>\n",
       "      <td>17767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17765</th>\n",
       "      <td>17768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17766</th>\n",
       "      <td>17769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17767</th>\n",
       "      <td>17770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17768 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      itemid\n",
       "0          1\n",
       "1          2\n",
       "2          3\n",
       "3          4\n",
       "4          5\n",
       "...      ...\n",
       "17763  17766\n",
       "17764  17767\n",
       "17765  17768\n",
       "17766  17769\n",
       "17767  17770\n",
       "\n",
       "[17768 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv(os.path.join(ds_path, 'unique_iId.txt'))\n",
    "items['iId']=items['iId'].apply(str)\n",
    "items.rename({'iId': 'itemid'}, axis=1, inplace=True)\n",
    "\n",
    "items.to_json(os.path.join(ds_path_out, 'items.json'))\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b3779e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = train['itemid'].isin(test['itemid'])\n",
    "\n",
    "result.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-premium",
   "metadata": {},
   "source": [
    "Purchases and grouped purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "specific-welding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userid                                            itemids\n",
      "0  296532  172,294,328,456,526,562,983,1193,1218,1404,161...\n",
      "1  292402  174,298,312,634,687,987,1041,1312,1643,2126,22...\n",
      "2   37677  1142,1426,1516,1797,2184,2198,2578,2780,3104,3...\n",
      "3  188370  190,196,472,569,983,1903,2035,2120,2150,2170,2...\n",
      "4  338669  759,4430,5315,6035,7603,9324,11520,11817,13072...\n"
     ]
    }
   ],
   "source": [
    "interactions = full\n",
    "gc.collect()\n",
    "\n",
    "interactions['itemid'] = interactions['itemid'].apply(str)\n",
    "interactions['userid'] = interactions['userid'].apply(str)\n",
    "interactions.reset_index(drop=True, inplace=True)\n",
    "interactions.to_json(os.path.join(ds_path_out, 'purchases.json'))\n",
    "purch = interactions\n",
    "\n",
    "interactions['itemids'] = interactions[['userid','itemid']].groupby(['userid'])['itemid'].transform(lambda x: ','.join(x))\n",
    "iii = interactions[['userid','itemids']].drop_duplicates()\n",
    "iii.reset_index(drop=True, inplace=True)\n",
    "iii.to_json(os.path.join(ds_path_out, 'purchases_txt.json'))\n",
    "print(iii.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557d20d",
   "metadata": {},
   "source": [
    "Keep only users with 5 or more interactions.\n",
    "\n",
    "Purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493894aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases=purch#pd.read_json(os.path.join(ds_path_out, 'purchases.json'))\n",
    "gc.collect()\n",
    "\n",
    "purchases['userid'] = purchases.userid.apply(str)\n",
    "purchases['itemid'] = purchases.itemid.apply(str)\n",
    "#purchases_item_counts = purchases[['uId','iId']]\n",
    "#purchases_user_counts = purchases[['uId','iId']]\n",
    "purchases_user_count = purchases.groupby(['userid']).size().to_frame('nr_of_purchases').reset_index()\n",
    "purchases_user_count = purchases_user_count.sort_values(by=['nr_of_purchases'], ascending=False)\n",
    "print(len(purchases_user_count))\n",
    "pu5=purchases_user_count#[purchases_user_count.nr_of_purchases>=5]\n",
    "print(len(purchases_user_count))\n",
    "print(len(pu5))\n",
    "gc.collect()\n",
    "\n",
    "purchases_pu5 = purchases[purchases.userid.isin(pu5.userid)]\n",
    "purchases_item_count_pu5 = purchases_pu5.groupby(['itemid']).size().to_frame('nr_of_purchases').reset_index()\n",
    "purchases_item_count_pu5 = purchases_item_count_pu5.sort_values(by=['nr_of_purchases'], ascending=False)\n",
    "print(len(purchases_item_count_pu5))\n",
    "\n",
    "#purchases_pu5.to_json(os.path.join(ds_path_out, 'purchases_pu5.json'))\n",
    "purchases.to_json(os.path.join(ds_path_out, 'purchases_pu5.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d210a7",
   "metadata": {},
   "source": [
    "Grouped purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_pu5['itemids'] = purchases_pu5[['userid','itemid']].groupby(['userid'])['itemid'].transform(lambda x: ','.join(x))\n",
    "iii = purchases_pu5[['userid','itemids']].drop_duplicates()\n",
    "iii['uId']=iii['userid'].apply(str)\n",
    "iii = iii[['userid','itemids']]\n",
    "iii.to_json(os.path.join(ds_path_out, 'purchases_txt_pu5.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-source",
   "metadata": {},
   "source": [
    "Users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "iii['userid'].to_frame().to_json(os.path.join(ds_path_out, 'users_pu5.json'))\n",
    "print(iii['userid'].to_frame().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-citizenship",
   "metadata": {},
   "source": [
    "Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "#items[items.itemid.isin(purchases_item_count_pu5.itemid)].to_json(\"items_pu5.json\")\n",
    "items[items.itemid.isin(items.itemid)].to_json(os.path.join(ds_path_out, 'items_pu5.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-saying",
   "metadata": {},
   "source": [
    "Items sorted by number of interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_item_count_pu5.to_json(os.path.join(ds_path_out, 'items_sorted_pu5.json'))\n",
    "purchases_item_count_pu5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-center",
   "metadata": {},
   "source": [
    "Users sorted by number of interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "pu5.to_json(os.path.join(ds_path_out, 'users_sorted_pu5.json'))\n",
    "pu5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-closer",
   "metadata": {},
   "source": [
    "Create train, val and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#users = pd.read_json('users_pu5.json')\n",
    "#shuffled_users = users.sample(frac=1., random_state=42)\n",
    "test_users = test['userid'].to_frame().drop_duplicates(subset=['userid'])\n",
    "val_users = val['userid'].to_frame().drop_duplicates(subset=['userid'])\n",
    "train_users = train['userid'].to_frame().drop_duplicates(subset=['userid'])\n",
    "\n",
    "test_users.to_json(os.path.join(ds_path_out, \"test_users.json\"))\n",
    "print(test_users.head())\n",
    "val_users.to_json(os.path.join(ds_path_out, \"val_users.json\"))\n",
    "print(val_users.head())\n",
    "train_users.to_json(os.path.join(ds_path_out, \"train_users.json\"))\n",
    "print(train_users.head())\n",
    "\n",
    "len(train_users),len(val_users),len(test_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-cooler",
   "metadata": {},
   "source": [
    "List of generated json files with preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/ubuntu/vasp/Datasets/netflix/preprocessed_vasp/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56280edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
